import torch
import torch.nn as nn
import cv2
import numpy as np
from models.backbones.FSGNet import FSGNet
from models import dataloader as dataloader_hub
import argparse
from PIL import Image
import os


class SimpleRegionGrowing:
    """ç®€å•åŒºåŸŸç”Ÿé•¿ç±»"""
    def __init__(self, mu_f=0.0789, sigma_f=0.0774, alpha=1.0):
        self.mu_f = mu_f
        self.sigma_f = sigma_f  
        self.alpha = alpha
        self.vessel_threshold = mu_f + alpha * sigma_f
    
    def preprocess_image(self, rgb_image):
        """é¢„å¤„ç†å•å¼ å›¾åƒ"""
        # rgb_image: [3, H, W] tensor
        green_channel = rgb_image[1].cpu().numpy()  # [H, W]
        
        # å½’ä¸€åŒ–
        min_val, max_val = green_channel.min(), green_channel.max()
        if max_val > min_val:
            normalized = (green_channel - min_val) / (max_val - min_val)
        else:
            normalized = green_channel
        
        # èƒŒæ™¯å‡é™¤å¢å¼º
        background = cv2.GaussianBlur(normalized, (101, 101), 0)
        enhanced = np.clip(normalized - background, 0, 1)
        
        return enhanced
    
    def calculate_gradient(self, enhanced_image):
        """è®¡ç®—æ¢¯åº¦"""
        # Sobelç®—å­
        grad_x = cv2.Sobel(enhanced_image, cv2.CV_64F, 1, 0, ksize=3)
        grad_y = cv2.Sobel(enhanced_image, cv2.CV_64F, 0, 1, ksize=3)
        gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
        
        return gradient_magnitude
    
    def region_growing(self, fsg_prediction, gradient_magnitude, fsg_threshold):
        """åŒºåŸŸç”Ÿé•¿"""
        # fsg_prediction: [H, W] numpy array (0-1æ¦‚ç‡)
        
        # 1. å°†FSGé¢„æµ‹æ¦‚ç‡è½¬æ¢ä¸ºäºŒå€¼ç§å­ç‚¹
        seed_binary = (fsg_prediction > fsg_threshold).astype(np.uint8)
        print(f"Initial seed points: {seed_binary.sum()} pixels")
        
        if seed_binary.sum() == 0:
            print("No seed points found!")
            return np.zeros_like(fsg_prediction, dtype=np.float32)
        
        # 2. åŸºäºæ¢¯åº¦é˜ˆå€¼é€‰æ‹©å€™é€‰è¡€ç®¡åƒç´ 
        vessel_candidates = (gradient_magnitude >= self.vessel_threshold).astype(np.uint8)
        print(f"Vessel candidates (gradient >= {self.vessel_threshold:.4f}): {vessel_candidates.sum()} pixels")
        
        # 3. åŒºåŸŸç”Ÿé•¿ï¼šä»ç§å­ç‚¹æ‰©å±•åˆ°å€™é€‰åƒç´ 
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        grown_mask = seed_binary.copy()
        
        # è¿­ä»£æ‰©å±•ï¼šåªåœ¨å€™é€‰åƒç´ åŒºåŸŸå†…æ‰©å±•
        for i in range(5):
            # è†¨èƒ€å½“å‰æ©ç 
            dilated = cv2.dilate(grown_mask, kernel, iterations=1)
            # åªä¿ç•™åœ¨è¡€ç®¡å€™é€‰åŒºåŸŸå†…çš„æ‰©å±•
            new_grown = dilated * vessel_candidates
            
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ–°å¢é•¿
            if np.array_equal(new_grown, grown_mask):
                print(f"Converged after {i+1} iterations")
                break
            grown_mask = new_grown
        
        print(f"Final grown region: {grown_mask.sum()} pixels")
        return grown_mask.astype(np.float32)
    
    def create_circular_mask(self, image_shape):
        """åˆ›å»ºåœ†å½¢æ©ç ï¼Œå»é™¤è¾¹æ¡†åŒºåŸŸ"""
        h, w = image_shape
        center_y, center_x = h // 2, w // 2
        radius = min(center_y, center_x) * 0.9  # ç¨å¾®å°ä¸€ç‚¹é¿å…è¾¹ç¼˜
        
        Y, X = np.ogrid[:h, :w]
        mask = ((X - center_x) ** 2 + (Y - center_y) ** 2) <= radius ** 2
        return mask.astype(np.float32)
    
    def refine_prediction(self, fsg_output, original_image):
        """ç»†åŒ–FSGé¢„æµ‹ç»“æœ"""
        # fsg_output: [H, W] numpy array (FSGé¢„æµ‹æ¦‚ç‡ 0-1)
        # original_image: [3, H, W] tensor
        
        print(f"FSG prediction range: [{fsg_output.min():.3f}, {fsg_output.max():.3f}]")
        
        # åˆ›å»ºåœ†å½¢æ©ç å»é™¤è¾¹æ¡†
        circular_mask = self.create_circular_mask(fsg_output.shape)
        fsg_output_masked = fsg_output * circular_mask
        print(f"After circular masking: [{fsg_output_masked.min():.3f}, {fsg_output_masked.max():.3f}]")
        
        # 1. é¢„å¤„ç†å›¾åƒ
        enhanced = self.preprocess_image(original_image)
        enhanced_masked = enhanced * circular_mask  # åŒæ ·åº”ç”¨æ©ç 
        
        # 2. è®¡ç®—æ¢¯åº¦
        gradient = self.calculate_gradient(enhanced_masked)
        print(f"Gradient range: [{gradient.min():.3f}, {gradient.max():.3f}]")
        
        # 3. è°ƒæ•´FSGé˜ˆå€¼ - ä½¿ç”¨åŠ¨æ€é˜ˆå€¼è€Œä¸æ˜¯å›ºå®š0.5
        # è®¡ç®—FSGçš„ç»Ÿè®¡ä¿¡æ¯
        valid_pixels = fsg_output_masked[circular_mask > 0]
        if len(valid_pixels) > 0:
            fsg_mean = valid_pixels.mean()
            fsg_std = valid_pixels.std()
            # ä½¿ç”¨å‡å€¼ + æ ‡å‡†å·®ä½œä¸ºé˜ˆå€¼ï¼Œæ›´é€‚åº”å½“å‰å›¾åƒ
            fsg_threshold = fsg_mean + 0.5 * fsg_std
            print(f"Dynamic FSG threshold: {fsg_threshold:.3f} (mean={fsg_mean:.3f}, std={fsg_std:.3f})")
        else:
            fsg_threshold = 0.5
            print(f"Using default FSG threshold: {fsg_threshold:.3f}")
        
        # 4. åŒºåŸŸç”Ÿé•¿ï¼šä½¿ç”¨åŠ¨æ€é˜ˆå€¼çš„FSGé¢„æµ‹ä½œä¸ºç§å­ç‚¹
        grown_result = self.region_growing(fsg_output_masked, gradient, fsg_threshold)
        
        # 5. èåˆç­–ç•¥ï¼šå–å¹¶é›†ï¼ˆORæ“ä½œï¼‰
        fsg_binary = (fsg_output_masked > fsg_threshold).astype(np.float32)
        final_result = np.logical_or(fsg_binary, grown_result).astype(np.float32)
        
        # åº”ç”¨åœ†å½¢æ©ç åˆ°æœ€ç»ˆç»“æœ
        final_result = final_result * circular_mask
        
        print(f"FSG binary pixels: {fsg_binary.sum():.0f}")
        print(f"Region grown pixels: {grown_result.sum():.0f}")
        print(f"Final result pixels: {final_result.sum():.0f}")
        print(f"Net gain: {final_result.sum() - fsg_binary.sum():.0f} pixels")
        
        return final_result


def create_overlay_image(original_image, prediction, ground_truth=None, colors=None):
    """åˆ›å»ºå åŠ å¯è§†åŒ–å›¾åƒ
    
    Args:
        original_image: åŸå§‹å›¾åƒ [H, W, 3] numpy array (0-1)
        prediction: é¢„æµ‹ç»“æœ [H, W] numpy array (0-1)
        ground_truth: çœŸå®æ ‡ç­¾ [H, W] numpy array (0-1), å¯é€‰
        colors: é¢œè‰²é…ç½®å­—å…¸
    
    Returns:
        overlay_image: å åŠ åçš„å›¾åƒ [H, W, 3] numpy array (0-1)
    """
    if colors is None:
        colors = {
            'prediction': [0, 1, 0],      # ç»¿è‰² - é¢„æµ‹
            'ground_truth': [1, 0, 0],    # çº¢è‰² - çœŸå®æ ‡ç­¾
            'both': [1, 1, 0],            # é»„è‰² - é‡å åŒºåŸŸ
            'alpha': 0.6                  # é€æ˜åº¦
        }
    
    # ç¡®ä¿è¾“å…¥æ˜¯numpyæ•°ç»„
    if isinstance(original_image, torch.Tensor):
        original_image = original_image.cpu().numpy()
    if isinstance(prediction, torch.Tensor):
        prediction = prediction.cpu().numpy()
    if ground_truth is not None and isinstance(ground_truth, torch.Tensor):
        ground_truth = ground_truth.cpu().numpy()
    
    # è½¬æ¢ä¸ºRGBæ ¼å¼ [H, W, 3]
    if original_image.ndim == 3 and original_image.shape[0] == 3:
        original_image = original_image.transpose(1, 2, 0)
    
    # åˆ›å»ºå åŠ å›¾åƒ
    overlay = original_image.copy()
    
    # äºŒå€¼åŒ–é¢„æµ‹ç»“æœ
    pred_binary = prediction > 0.5
    
    if ground_truth is not None:
        # äºŒå€¼åŒ–çœŸå®æ ‡ç­¾
        gt_binary = ground_truth > 0.5
        
        # åˆ›å»ºä¸åŒåŒºåŸŸçš„æ©ç 
        both_mask = pred_binary & gt_binary      # ä¸¤è€…éƒ½æœ‰ - é»„è‰²
        pred_only = pred_binary & (~gt_binary)   # åªæœ‰é¢„æµ‹ - ç»¿è‰²
        gt_only = gt_binary & (~pred_binary)     # åªæœ‰çœŸå®æ ‡ç­¾ - çº¢è‰²
        
        # åº”ç”¨é¢œè‰²
        alpha = colors['alpha']
        
        # é»„è‰²åŒºåŸŸ (é‡å )
        overlay[both_mask] = (1 - alpha) * overlay[both_mask] + alpha * np.array(colors['both'])
        
        # ç»¿è‰²åŒºåŸŸ (ä»…é¢„æµ‹)
        overlay[pred_only] = (1 - alpha) * overlay[pred_only] + alpha * np.array(colors['prediction'])
        
        # çº¢è‰²åŒºåŸŸ (ä»…çœŸå®æ ‡ç­¾)
        overlay[gt_only] = (1 - alpha) * overlay[gt_only] + alpha * np.array(colors['ground_truth'])
        
    else:
        # åªæœ‰é¢„æµ‹ç»“æœ
        alpha = colors['alpha']
        overlay[pred_binary] = (1 - alpha) * overlay[pred_binary] + alpha * np.array(colors['prediction'])
    
    return np.clip(overlay, 0, 1)


def create_refinement_improvement_overlay(original_image, fsg_prediction, refined_prediction, ground_truth):
    """åˆ›å»ºæ˜¾ç¤ºç»†åŒ–æ”¹è¿›æ•ˆæœçš„å åŠ å›¾
    
    ä¸“é—¨æ˜¾ç¤ºç»†åŒ–è¿‡ç¨‹ä¸­çš„æ”¹è¿›æƒ…å†µï¼š
    - ç»¿è‰²ï¼šç»†åŒ–æ–°å¢çš„æ­£ç¡®åƒç´ ï¼ˆçœŸæ­£çš„æ”¹è¿›ï¼‰
    - çº¢è‰²ï¼šç»†åŒ–æ–°å¢çš„é”™è¯¯åƒç´ ï¼ˆå‡é˜³æ€§å¢åŠ ï¼‰
    - è“è‰²ï¼šç»†åŒ–ä¸¢å¤±çš„æ­£ç¡®åƒç´ ï¼ˆçœŸé˜³æ€§ä¸¢å¤±ï¼‰
    - é»„è‰²ï¼šç»†åŒ–ä¸¢å¤±çš„é”™è¯¯åƒç´ ï¼ˆå‡é˜³æ€§å‡å°‘ï¼Œè¿™æ˜¯å¥½äº‹ï¼‰
    
    Args:
        original_image: åŸå§‹å›¾åƒ [H, W, 3]
        fsg_prediction: FSGé¢„æµ‹ç»“æœ [H, W]
        refined_prediction: ç»†åŒ–é¢„æµ‹ç»“æœ [H, W]
        ground_truth: çœŸå®æ ‡ç­¾ [H, W]
    
    Returns:
        overlay_image: æ”¹è¿›æ•ˆæœå åŠ å›¾
        improvement_stats: æ”¹è¿›ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    # ç¡®ä¿è¾“å…¥æ˜¯numpyæ•°ç»„
    if isinstance(original_image, torch.Tensor):
        original_image = original_image.cpu().numpy()
    if isinstance(fsg_prediction, torch.Tensor):
        fsg_prediction = fsg_prediction.cpu().numpy()
    if isinstance(refined_prediction, torch.Tensor):
        refined_prediction = refined_prediction.cpu().numpy()
    if isinstance(ground_truth, torch.Tensor):
        ground_truth = ground_truth.cpu().numpy()
    
    # è½¬æ¢ä¸ºRGBæ ¼å¼
    if original_image.ndim == 3 and original_image.shape[0] == 3:
        original_image = original_image.transpose(1, 2, 0)
    
    # äºŒå€¼åŒ–
    fsg_binary = fsg_prediction > 0.5
    refined_binary = refined_prediction > 0.5
    gt_binary = ground_truth > 0.5
    
    # è®¡ç®—å˜åŒ–åŒºåŸŸ
    added_pixels = refined_binary & (~fsg_binary)     # ç»†åŒ–æ–°å¢çš„åƒç´ 
    removed_pixels = fsg_binary & (~refined_binary)   # ç»†åŒ–ç§»é™¤çš„åƒç´ 
    
    # åˆ†ææ–°å¢åƒç´ çš„æ­£ç¡®æ€§
    added_correct = added_pixels & gt_binary          # æ–°å¢çš„æ­£ç¡®åƒç´ ï¼ˆçœŸæ­£çš„æ”¹è¿›ï¼‰
    added_incorrect = added_pixels & (~gt_binary)     # æ–°å¢çš„é”™è¯¯åƒç´ ï¼ˆå‡é˜³æ€§å¢åŠ ï¼‰
    
    # åˆ†æç§»é™¤åƒç´ çš„å½±å“
    removed_correct = removed_pixels & gt_binary      # ç§»é™¤çš„æ­£ç¡®åƒç´ ï¼ˆçœŸé˜³æ€§ä¸¢å¤±ï¼‰
    removed_incorrect = removed_pixels & (~gt_binary) # ç§»é™¤çš„é”™è¯¯åƒç´ ï¼ˆå‡é˜³æ€§å‡å°‘ï¼Œå¥½äº‹ï¼‰
    
    # åˆ›å»ºå åŠ å›¾åƒ
    overlay = original_image.copy()
    alpha = 0.7
    
    # åº”ç”¨é¢œè‰²ç¼–ç 
    overlay[added_correct] = (1 - alpha) * overlay[added_correct] + alpha * np.array([0, 1, 0])      # ç»¿è‰² - æ­£ç¡®æ”¹è¿›
    overlay[added_incorrect] = (1 - alpha) * overlay[added_incorrect] + alpha * np.array([1, 0, 0])  # çº¢è‰² - é”™è¯¯å¢åŠ 
    overlay[removed_correct] = (1 - alpha) * overlay[removed_correct] + alpha * np.array([0, 0, 1])  # è“è‰² - æ­£ç¡®ä¸¢å¤±
    overlay[removed_incorrect] = (1 - alpha) * overlay[removed_incorrect] + alpha * np.array([1, 1, 0]) # é»„è‰² - é”™è¯¯å‡å°‘
    
    # ç»Ÿè®¡ä¿¡æ¯
    improvement_stats = {
        'added_correct': int(added_correct.sum()),
        'added_incorrect': int(added_incorrect.sum()),
        'removed_correct': int(removed_correct.sum()),
        'removed_incorrect': int(removed_incorrect.sum()),
        'net_improvement': int(added_correct.sum() - removed_correct.sum()),
        'net_false_positive_change': int(added_incorrect.sum() - removed_incorrect.sum())
    }
    
    return np.clip(overlay, 0, 1), improvement_stats


def create_comparison_overlay(original_image, fsg_prediction, refined_prediction, ground_truth=None):
    """åˆ›å»ºFSG vs ç»†åŒ–ç»“æœçš„å¯¹æ¯”å åŠ å›¾
    
    Args:
        original_image: åŸå§‹å›¾åƒ
        fsg_prediction: FSGé¢„æµ‹ç»“æœ
        refined_prediction: ç»†åŒ–åçš„é¢„æµ‹ç»“æœ
        ground_truth: çœŸå®æ ‡ç­¾ (å¯é€‰)
    
    Returns:
        overlay_image: å¯¹æ¯”å åŠ å›¾
    """
    colors = {
        'fsg_only': [0, 0, 1],        # è“è‰² - ä»…FSG
        'refined_only': [1, 0, 0],    # çº¢è‰² - ä»…ç»†åŒ–ç»“æœ
        'both': [1, 0, 1],            # ç´«è‰² - ä¸¤è€…éƒ½æœ‰
        'alpha': 0.6
    }
    
    # ç¡®ä¿è¾“å…¥æ˜¯numpyæ•°ç»„
    if isinstance(original_image, torch.Tensor):
        original_image = original_image.cpu().numpy()
    if isinstance(fsg_prediction, torch.Tensor):
        fsg_prediction = fsg_prediction.cpu().numpy()
    if isinstance(refined_prediction, torch.Tensor):
        refined_prediction = refined_prediction.cpu().numpy()
    
    # è½¬æ¢ä¸ºRGBæ ¼å¼
    if original_image.ndim == 3 and original_image.shape[0] == 3:
        original_image = original_image.transpose(1, 2, 0)
    
    # åˆ›å»ºå åŠ å›¾åƒ
    overlay = original_image.copy()
    
    # äºŒå€¼åŒ–
    fsg_binary = fsg_prediction > 0.5
    refined_binary = refined_prediction > 0.5
    
    # åˆ›å»ºä¸åŒåŒºåŸŸçš„æ©ç 
    both_mask = fsg_binary & refined_binary          # ä¸¤è€…éƒ½æœ‰ - ç´«è‰²
    fsg_only = fsg_binary & (~refined_binary)        # ä»…FSG - è“è‰²
    refined_only = refined_binary & (~fsg_binary)    # ä»…ç»†åŒ– - çº¢è‰²
    
    # åº”ç”¨é¢œè‰²
    alpha = colors['alpha']
    
    # ç´«è‰²åŒºåŸŸ (é‡å )
    overlay[both_mask] = (1 - alpha) * overlay[both_mask] + alpha * np.array(colors['both'])
    
    # è“è‰²åŒºåŸŸ (ä»…FSG)
    overlay[fsg_only] = (1 - alpha) * overlay[fsg_only] + alpha * np.array(colors['fsg_only'])
    
    # çº¢è‰²åŒºåŸŸ (ä»…ç»†åŒ–)
    overlay[refined_only] = (1 - alpha) * overlay[refined_only] + alpha * np.array(colors['refined_only'])
    
    return np.clip(overlay, 0, 1)


def load_fsg_model(model_path, device):
    """åŠ è½½FSGæ¨¡å‹"""
    model = FSGNet(channel=3, n_classes=1, base_c=64, depths=[3, 3, 9, 3], kernel_size=3)
    
    # åŠ è½½æƒé‡
    checkpoint = torch.load(model_path, map_location='cpu')
    
    # å¤„ç†DataParallelä¿å­˜çš„æƒé‡ (å»æ‰module.FSGNet.å‰ç¼€)
    state_dict = {}
    for key, value in checkpoint.items():
        if key.startswith('module.FSGNet.'):
            # å»æ‰ 'module.FSGNet.' å‰ç¼€
            new_key = key[len('module.FSGNet.'):]
            state_dict[new_key] = value
        elif key.startswith('module.'):
            # å»æ‰ 'module.' å‰ç¼€
            new_key = key[len('module.'):]
            state_dict[new_key] = value
        else:
            state_dict[key] = value
    
    model.load_state_dict(state_dict)
    model.to(device)
    model.eval()
    print(f"Successfully loaded FSG model with {len(state_dict)} parameters")
    return model


def find_ground_truth(img_file, possible_gt_dirs):
    """æŸ¥æ‰¾å¯¹åº”çš„çœŸå®æ ‡ç­¾æ–‡ä»¶"""
    base_name = os.path.splitext(img_file)[0]
    
    # å¸¸è§çš„æ ‡ç­¾æ–‡ä»¶å‘½åæ¨¡å¼
    possible_names = [
        f"{base_name}_manual1.gif",
        f"{base_name}_manual1.png",
        f"{base_name}_manual1.tif",
        f"{base_name}_gt.png",
        f"{base_name}_gt.gif",
        f"{base_name}_gt.tif",
        f"{base_name}.png",
        f"{base_name}.gif",
        f"{base_name}.tif"
    ]
    
    for gt_dir in possible_gt_dirs:
        if os.path.exists(gt_dir):
            for possible_name in possible_names:
                gt_path = os.path.join(gt_dir, possible_name)
                if os.path.exists(gt_path):
                    return gt_path
    return None


def inference_with_region_growing():
    # é…ç½® - å…ˆå°è¯•valç›®å½•ï¼Œå¦‚æœä¸ºç©ºåˆ™ä½¿ç”¨trainç›®å½•
    fsg_model_path = '/root/FSG-Net-pytorch/model_ckpts/FSG-Net-DRIVE.pt'
    
    # å°è¯•å¤šä¸ªå¯èƒ½çš„æ•°æ®è·¯å¾„
    possible_paths = [
        '/root/FSG-Net-pytorch/data/DRIVE/val/input',
        '/root/FSG-Net-pytorch/data/DRIVE/train/input',
        '/root/FSG-Net-pytorch/data/DRIVE/val',
        '/root/FSG-Net-pytorch/data/DRIVE/train'
    ]
    
    # å¯èƒ½çš„çœŸå®æ ‡ç­¾è·¯å¾„
    possible_gt_dirs = [
        '/root/FSG-Net-pytorch/data/DRIVE/val/gt',
        '/root/FSG-Net-pytorch/data/DRIVE/train/gt',
        '/root/FSG-Net-pytorch/data/DRIVE/val/label',
        '/root/FSG-Net-pytorch/data/DRIVE/train/label',
        '/root/FSG-Net-pytorch/data/DRIVE/val/mask',
        '/root/FSG-Net-pytorch/data/DRIVE/train/mask'
    ]
    
    test_data_path = None
    for path in possible_paths:
        if os.path.exists(path):
            files = [f for f in os.listdir(path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff', '.bmp'))]
            if len(files) > 0:
                test_data_path = path
                print(f"Found {len(files)} images in: {path}")
                break
            else:
                print(f"Path exists but no images found: {path}")
        else:
            print(f"Path does not exist: {path}")
    
    if test_data_path is None:
        print("No valid image directory found!")
        print("Please check your data structure or put some test images in one of these directories:")
        for path in possible_paths:
            print(f"  {path}")
        return
    
    output_dir = './region_growing_results'
    
    # åŒºåŸŸç”Ÿé•¿å‚æ•°
    mu_f = 0.0789
    sigma_f = 0.0774
    alpha = 1.0
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    
    # åŠ è½½FSGæ¨¡å‹
    print("Loading FSG-Net model...")
    fsg_model = load_fsg_model(fsg_model_path, device)
    
    # åˆå§‹åŒ–åŒºåŸŸç”Ÿé•¿
    region_grower = SimpleRegionGrowing(mu_f, sigma_f, alpha)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    os.makedirs(f"{output_dir}/fsg_original", exist_ok=True)
    os.makedirs(f"{output_dir}/region_grown", exist_ok=True)
    os.makedirs(f"{output_dir}/overlay_with_gt", exist_ok=True)
    os.makedirs(f"{output_dir}/overlay_fsg_vs_refined", exist_ok=True)
    os.makedirs(f"{output_dir}/overlay_fsg_only", exist_ok=True)
    os.makedirs(f"{output_dir}/overlay_refined_only", exist_ok=True)
    os.makedirs(f"{output_dir}/refinement_improvement", exist_ok=True)
    
    # æŸ¥æ‰¾å›¾åƒæ–‡ä»¶ - ç¡®ä¿åŒ…å«.tifæ ¼å¼
    all_files = os.listdir(test_data_path)
    image_files = [f for f in all_files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff', '.bmp'))]
    
    print(f"Found {len(all_files)} total files in {test_data_path}")
    print(f"Found {len(image_files)} image files")
    
    if len(image_files) == 0:
        print("No image files found! Listing all files in directory:")
        for f in all_files[:10]:  # æ˜¾ç¤ºå‰10ä¸ªæ–‡ä»¶
            print(f"  {f}")
        return
    
    print(f"Processing {len(image_files)} images...")
    
    # å¤„ç†æ¯å¼ å›¾åƒ
    for i, img_file in enumerate(image_files):
        print(f"Processing {i+1}/{len(image_files)}: {img_file}")
        
        try:
            # åŠ è½½å›¾åƒ
            img_path = os.path.join(test_data_path, img_file)
            image = Image.open(img_path).convert('RGB')
            print(f"  Image size: {image.size}")
            
            # è½¬æ¢ä¸ºtensorå¹¶å½’ä¸€åŒ–
            img_array = np.array(image) / 255.0
            img_tensor = torch.tensor(img_array.transpose(2, 0, 1), dtype=torch.float32).unsqueeze(0).to(device)
            print(f"  Tensor shape: {img_tensor.shape}")
            
            # æŸ¥æ‰¾å¯¹åº”çš„çœŸå®æ ‡ç­¾
            gt_path = find_ground_truth(img_file, possible_gt_dirs)
            ground_truth = None
            if gt_path:
                try:
                    gt_image = Image.open(gt_path).convert('L')
                    ground_truth = np.array(gt_image) / 255.0
                    print(f"  Found ground truth: {os.path.basename(gt_path)}")
                except Exception as e:
                    print(f"  Error loading ground truth: {e}")
                    ground_truth = None
            else:
                print(f"  No ground truth found for {img_file}")
            
            # FSGæ¨ç†
            with torch.no_grad():
                fsg_out1, fsg_out2, fsg_out3 = fsg_model(img_tensor)
                
                # FSGæ¨¡å‹çš„è¾“å‡ºå±‚å·²ç»æœ‰sigmoidï¼Œæ‰€ä»¥ä¸éœ€è¦å†æ¬¡sigmoid
                fsg_prediction = fsg_out1.squeeze().cpu().numpy()  # [H, W]
                print(f"  FSG prediction shape: {fsg_prediction.shape}")
                print(f"  FSG raw output range: [{fsg_prediction.min():.3f}, {fsg_prediction.max():.3f}]")
                
                # å¦‚æœè¾“å‡ºèŒƒå›´çœ‹èµ·æ¥å·²ç»æ˜¯æ¦‚ç‡ï¼Œåˆ™ç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™åº”ç”¨sigmoid
                if fsg_prediction.min() >= 0 and fsg_prediction.max() <= 1:
                    print("  Using FSG output directly (appears to be probabilities)")
                else:
                    print("  Applying sigmoid to FSG output")
                    fsg_prediction = 1 / (1 + np.exp(-np.clip(fsg_prediction, -50, 50)))
            
            # åŒºåŸŸç”Ÿé•¿ç»†åŒ–
            original_tensor = img_tensor.squeeze()  # [3, H, W]
            refined_prediction = region_grower.refine_prediction(fsg_prediction, original_tensor)
            
            # ä¿å­˜ç»“æœ
            base_name = os.path.splitext(img_file)[0]
            
            # ä¿å­˜FSGåŸå§‹ç»“æœ
            fsg_result_img = (fsg_prediction * 255).astype(np.uint8)
            Image.fromarray(fsg_result_img).save(f"{output_dir}/fsg_original/{base_name}_fsg.png")
            
            # ä¿å­˜åŒºåŸŸç”Ÿé•¿ç»†åŒ–ç»“æœ
            refined_result_img = (refined_prediction * 255).astype(np.uint8)
            Image.fromarray(refined_result_img).save(f"{output_dir}/region_grown/{base_name}_refined.png")
            
            # åˆ›å»ºå’Œä¿å­˜overlayå›¾åƒ
            
            # 1. FSGé¢„æµ‹ä¸çœŸå®æ ‡ç­¾çš„overlay
            fsg_overlay = create_overlay_image(img_array, fsg_prediction, ground_truth)
            fsg_overlay_img = (fsg_overlay * 255).astype(np.uint8)
            Image.fromarray(fsg_overlay_img).save(f"{output_dir}/overlay_fsg_only/{base_name}_fsg_overlay.png")
            
            # 2. ç»†åŒ–ç»“æœä¸çœŸå®æ ‡ç­¾çš„overlay
            refined_overlay = create_overlay_image(img_array, refined_prediction, ground_truth)
            refined_overlay_img = (refined_overlay * 255).astype(np.uint8)
            Image.fromarray(refined_overlay_img).save(f"{output_dir}/overlay_refined_only/{base_name}_refined_overlay.png")
            
            # 3. FSG vs ç»†åŒ–ç»“æœçš„å¯¹æ¯”overlay
            comparison_overlay = create_comparison_overlay(img_array, fsg_prediction, refined_prediction, ground_truth)
            comparison_overlay_img = (comparison_overlay * 255).astype(np.uint8)
            Image.fromarray(comparison_overlay_img).save(f"{output_dir}/overlay_fsg_vs_refined/{base_name}_comparison.png")
            
            # 4. å¦‚æœæœ‰çœŸå®æ ‡ç­¾ï¼Œåˆ›å»ºç»¼åˆå¯¹æ¯”å›¾
            if ground_truth is not None:
                # åˆ›å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰ä¿¡æ¯çš„ç»¼åˆoverlay
                colors = {
                    'prediction': [0, 1, 0],      # ç»¿è‰² - ç»†åŒ–é¢„æµ‹
                    'ground_truth': [1, 0, 0],    # çº¢è‰² - çœŸå®æ ‡ç­¾
                    'both': [1, 1, 0],            # é»„è‰² - é‡å åŒºåŸŸ
                    'alpha': 0.5
                }
                gt_overlay = create_overlay_image(img_array, refined_prediction, ground_truth, colors)
                gt_overlay_img = (gt_overlay * 255).astype(np.uint8)
                Image.fromarray(gt_overlay_img).save(f"{output_dir}/overlay_with_gt/{base_name}_with_gt.png")
                
                # 5. åˆ›å»ºç»†åŒ–æ”¹è¿›æ•ˆæœå›¾ï¼ˆæœ€é‡è¦çš„æ–°å¢åŠŸèƒ½ï¼‰
                improvement_overlay, improvement_stats = create_refinement_improvement_overlay(
                    img_array, fsg_prediction, refined_prediction, ground_truth
                )
                improvement_overlay_img = (improvement_overlay * 255).astype(np.uint8)
                Image.fromarray(improvement_overlay_img).save(f"{output_dir}/refinement_improvement/{base_name}_improvement.png")
                
                # æ‰“å°æ”¹è¿›ç»Ÿè®¡ä¿¡æ¯
                print(f"  === ç»†åŒ–æ”¹è¿›ç»Ÿè®¡ ===")
                print(f"  âœ… æ–°å¢æ­£ç¡®åƒç´ : {improvement_stats['added_correct']}")
                print(f"  âŒ æ–°å¢é”™è¯¯åƒç´ : {improvement_stats['added_incorrect']}")
                print(f"  âš ï¸  ä¸¢å¤±æ­£ç¡®åƒç´ : {improvement_stats['removed_correct']}")
                print(f"  âœ… å‡å°‘é”™è¯¯åƒç´ : {improvement_stats['removed_incorrect']}")
                print(f"  ğŸ“ˆ å‡€æ”¹è¿›(æ­£ç¡®åƒç´ ): {improvement_stats['net_improvement']}")
                print(f"  ğŸ“Š å‡é˜³æ€§å‡€å˜åŒ–: {improvement_stats['net_false_positive_change']}")
            
            print(f"  Results saved for {base_name}")
            print("-" * 50)
            
        except Exception as e:
            print(f"  Error processing {img_file}: {str(e)}")
            continue
    
    print(f"All results saved to {output_dir}")
    print(f"Check the following directories:")
    print(f"  - {output_dir}/fsg_original/ (FSGåŸå§‹ç»“æœ)")
    print(f"  - {output_dir}/region_grown/ (åŒºåŸŸç”Ÿé•¿ç»†åŒ–ç»“æœ)")
    print(f"  - {output_dir}/overlay_fsg_only/ (FSGä¸çœŸå®æ ‡ç­¾overlay)")
    print(f"  - {output_dir}/overlay_refined_only/ (ç»†åŒ–ç»“æœä¸çœŸå®æ ‡ç­¾overlay)")
    print(f"  - {output_dir}/overlay_fsg_vs_refined/ (FSG vs ç»†åŒ–ç»“æœå¯¹æ¯”)")
    print(f"  - {output_dir}/overlay_with_gt/ (ç»†åŒ–ç»“æœä¸çœŸå®æ ‡ç­¾ç»¼åˆå¯¹æ¯”)")
    print(f"  - {output_dir}/refinement_improvement/ (ç»†åŒ–æ”¹è¿›æ•ˆæœå›¾ â­)")
    print("\nOverlayé¢œè‰²è¯´æ˜:")
    print("  FSG vs ç»†åŒ–å¯¹æ¯”å›¾: è“è‰²=ä»…FSG, çº¢è‰²=ä»…ç»†åŒ–, ç´«è‰²=ä¸¤è€…é‡å ")
    print("  ä¸çœŸå®æ ‡ç­¾å¯¹æ¯”å›¾: ç»¿è‰²=é¢„æµ‹, çº¢è‰²=çœŸå®æ ‡ç­¾, é»„è‰²=æ­£ç¡®é¢„æµ‹")
    print("  ç»†åŒ–æ”¹è¿›æ•ˆæœå›¾:")
    print("    ğŸŸ¢ ç»¿è‰² = ç»†åŒ–æ–°å¢çš„æ­£ç¡®åƒç´  (çœŸæ­£çš„æ”¹è¿›!)")
    print("    ğŸ”´ çº¢è‰² = ç»†åŒ–æ–°å¢çš„é”™è¯¯åƒç´  (å‡é˜³æ€§å¢åŠ )")
    print("    ğŸ”µ è“è‰² = ç»†åŒ–ä¸¢å¤±çš„æ­£ç¡®åƒç´  (çœŸé˜³æ€§ä¸¢å¤±)")
    print("    ğŸŸ¡ é»„è‰² = ç»†åŒ–å‡å°‘çš„é”™è¯¯åƒç´  (å‡é˜³æ€§å‡å°‘,å¥½äº‹)")


if __name__ == "__main__":
    inference_with_region_growing()