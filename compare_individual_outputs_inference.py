import torch
import torch.nn as nn
import cv2
import numpy as np
from models.backbones.FSGNet import FSGNet
import torchvision.transforms.functional as tf
import argparse
from PIL import Image
import os


class SimpleRegionGrowing:
    """ç®€å•åŒºåŸŸç”Ÿé•¿ç±»"""
    def __init__(self, mu_f=0.0789, sigma_f=0.0774, alpha=1.0):
        self.mu_f = mu_f
        self.sigma_f = sigma_f  
        self.alpha = alpha
        self.vessel_threshold = mu_f + alpha * sigma_f
    
    def preprocess_image(self, rgb_image):
        """é¢„å¤„ç†å•å¼ å›¾åƒ"""
        # rgb_image: [3, H, W] tensor
        green_channel = rgb_image[1].cpu().numpy()  # [H, W]
        
        # å½’ä¸€åŒ–
        min_val, max_val = green_channel.min(), green_channel.max()
        if max_val > min_val:
            normalized = (green_channel - min_val) / (max_val - min_val)
        else:
            normalized = green_channel
        
        # èƒŒæ™¯å‡é™¤å¢å¼º
        background = cv2.GaussianBlur(normalized, (101, 101), 0)
        enhanced = np.clip(normalized - background, 0, 1)
        
        return enhanced
    
    def calculate_gradient(self, enhanced_image):
        """è®¡ç®—æ¢¯åº¦"""
        # Sobelç®—å­
        grad_x = cv2.Sobel(enhanced_image, cv2.CV_64F, 1, 0, ksize=3)
        grad_y = cv2.Sobel(enhanced_image, cv2.CV_64F, 0, 1, ksize=3)
        gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
        
        return gradient_magnitude
    
    def region_growing(self, fsg_prediction, gradient_magnitude, fsg_threshold):
        """åŒºåŸŸç”Ÿé•¿"""
        # fsg_prediction: [H, W] numpy array (0-1æ¦‚ç‡)
        
        # 1. å°†FSGé¢„æµ‹æ¦‚ç‡è½¬æ¢ä¸ºäºŒå€¼ç§å­ç‚¹
        seed_binary = (fsg_prediction > fsg_threshold).astype(np.uint8)
        print(f"    Initial seed points: {seed_binary.sum()} pixels")
        
        if seed_binary.sum() == 0:
            print("    No seed points found!")
            return np.zeros_like(fsg_prediction, dtype=np.float32)
        
        # 2. åŸºäºæ¢¯åº¦é˜ˆå€¼é€‰æ‹©å€™é€‰è¡€ç®¡åƒç´ 
        vessel_candidates = (gradient_magnitude >= self.vessel_threshold).astype(np.uint8)
        print(f"    Vessel candidates (gradient >= {self.vessel_threshold:.4f}): {vessel_candidates.sum()} pixels")
        
        # 3. åŒºåŸŸç”Ÿé•¿ï¼šä»ç§å­ç‚¹æ‰©å±•åˆ°å€™é€‰åƒç´ 
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        grown_mask = seed_binary.copy()
        
        # è¿­ä»£æ‰©å±•ï¼šåªåœ¨å€™é€‰åƒç´ åŒºåŸŸå†…æ‰©å±•
        for i in range(5):
            # è†¨èƒ€å½“å‰æ©ç 
            dilated = cv2.dilate(grown_mask, kernel, iterations=1)
            # åªä¿ç•™åœ¨è¡€ç®¡å€™é€‰åŒºåŸŸå†…çš„æ‰©å±•
            new_grown = dilated * vessel_candidates
            
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ–°å¢é•¿
            if np.array_equal(new_grown, grown_mask):
                print(f"    Converged after {i+1} iterations")
                break
            grown_mask = new_grown
        
        print(f"    Final grown region: {grown_mask.sum()} pixels")
        return grown_mask.astype(np.float32)
    
    def get_dynamic_threshold(self, prediction):
        """è®¡ç®—åŠ¨æ€é˜ˆå€¼ - ä¸ä½¿ç”¨åœ†å½¢æ©ç """
        if len(prediction[prediction > 0]) > 0:
            pred_mean = prediction.mean()
            pred_std = prediction.std()
            # ä½¿ç”¨å‡å€¼ + 0.5 * æ ‡å‡†å·®ä½œä¸ºé˜ˆå€¼
            threshold = pred_mean + 0.5 * pred_std
            print(f"    Dynamic threshold: {threshold:.3f} (mean={pred_mean:.3f}, std={pred_std:.3f})")
        else:
            threshold = 0.5
            print(f"    Using default threshold: {threshold:.3f}")
        return threshold
    
    def refine_prediction(self, fsg_output, original_image, output_name="output"):
        """ç»†åŒ–FSGé¢„æµ‹ç»“æœ"""
        # fsg_output: [H, W] numpy array (FSGé¢„æµ‹æ¦‚ç‡ 0-1)
        # original_image: [3, H, W] tensor (å·²ç»è¿‡ImageNetå½’ä¸€åŒ–)
        
        print(f"  {output_name} prediction range: [{fsg_output.min():.3f}, {fsg_output.max():.3f}]")
        
        # 1. åå½’ä¸€åŒ–å›¾åƒä»¥è¿›è¡Œæ¢¯åº¦è®¡ç®—
        if not hasattr(self, '_enhanced_cached'):
            # åå½’ä¸€åŒ–ImageNetæ ‡å‡†åŒ– - ç¡®ä¿åœ¨ç›¸åŒè®¾å¤‡ä¸Š
            mean = torch.tensor([0.485, 0.456, 0.406], device=original_image.device).view(3, 1, 1)
            std = torch.tensor([0.229, 0.224, 0.225], device=original_image.device).view(3, 1, 1)
            unnormalized_image = original_image * std + mean
            unnormalized_image = torch.clamp(unnormalized_image, 0, 1)
            
            enhanced = self.preprocess_image(unnormalized_image)
            gradient = self.calculate_gradient(enhanced)
            print(f"  Gradient range: [{gradient.min():.3f}, {gradient.max():.3f}]")
            
            # ç¼“å­˜ç»“æœï¼Œé¿å…é‡å¤è®¡ç®—
            self._enhanced_cached = enhanced
            self._gradient_cached = gradient
        else:
            enhanced = self._enhanced_cached
            gradient = self._gradient_cached
        
        # 2. è®¡ç®—åŠ¨æ€é˜ˆå€¼
        fsg_threshold = self.get_dynamic_threshold(fsg_output)
        
        # 3. åŒºåŸŸç”Ÿé•¿ï¼šä½¿ç”¨åŠ¨æ€é˜ˆå€¼çš„FSGé¢„æµ‹ä½œä¸ºç§å­ç‚¹
        grown_result = self.region_growing(fsg_output, gradient, fsg_threshold)
        
        # 4. èåˆç­–ç•¥ï¼šå–å¹¶é›†ï¼ˆORæ“ä½œï¼‰
        fsg_binary = (fsg_output > fsg_threshold).astype(np.float32)
        final_result = np.logical_or(fsg_binary, grown_result).astype(np.float32)
        
        print(f"  {output_name} FSG binary pixels: {fsg_binary.sum():.0f}")
        print(f"  {output_name} Region grown pixels: {grown_result.sum():.0f}")
        print(f"  {output_name} Final result pixels: {final_result.sum():.0f}")
        print(f"  {output_name} Net gain: {final_result.sum() - fsg_binary.sum():.0f} pixels")
        
        return final_result, fsg_binary, grown_result, fsg_threshold
    
    def clear_cache(self):
        """æ¸…é™¤ç¼“å­˜ï¼Œç”¨äºå¤„ç†æ–°å›¾åƒ"""
        if hasattr(self, '_enhanced_cached'):
            delattr(self, '_enhanced_cached')
        if hasattr(self, '_gradient_cached'):
            delattr(self, '_gradient_cached')


def preprocess_image_like_original(image):
    """æŒ‰ç…§åŸå§‹dataloaderæ–¹å¼é¢„å¤„ç†å›¾åƒ"""
    # 1. Resizeåˆ°608x608
    image = tf.resize(image, [608, 608])
    
    # 2. è½¬ä¸ºtensor
    image_tensor = tf.to_tensor(image)
    
    # 3. ImageNetå½’ä¸€åŒ–
    image_tensor = tf.normalize(image_tensor,
                               mean=[0.485, 0.456, 0.406],
                               std=[0.229, 0.224, 0.225])
    
    return image_tensor


def preprocess_target_like_original(target):
    """æŒ‰ç…§åŸå§‹dataloaderæ–¹å¼é¢„å¤„ç†æ ‡ç­¾"""
    # 1. Resizeåˆ°608x608
    target = tf.resize(target, [608, 608], interpolation=tf.InterpolationMode.NEAREST)
    
    # 2. è½¬ä¸ºtensor
    target_tensor = torch.tensor(np.array(target))
    
    # 3. äºŒå€¼åŒ–å¤„ç†
    target_tensor[target_tensor < 128] = 0
    target_tensor[target_tensor >= 128] = 1
    
    # 4. æ·»åŠ channelç»´åº¦
    target_tensor = target_tensor.unsqueeze(0)
    
    return target_tensor


def calculate_metrics_like_original(prediction, ground_truth):
    """æŒ‰ç…§åŸå§‹æ–¹å¼è®¡ç®—æŒ‡æ ‡"""
    # ç¡®ä¿éƒ½æ˜¯numpyæ•°ç»„
    if isinstance(prediction, torch.Tensor):
        prediction = prediction.cpu().numpy()
    if isinstance(ground_truth, torch.Tensor):
        ground_truth = ground_truth.cpu().numpy()
    
    # å±•å¹³
    pred_flat = prediction.flatten()
    gt_flat = ground_truth.flatten()
    
    # äºŒå€¼åŒ–é¢„æµ‹
    pred_binary = np.zeros_like(pred_flat)
    pred_binary[pred_flat > 0.5] = 1
    
    # è®¡ç®—æ··æ·†çŸ©é˜µ
    try:
        from sklearn.metrics import confusion_matrix
        tn, fp, fn, tp = confusion_matrix(y_true=gt_flat, y_pred=pred_binary).ravel()
    except:
        # ç®€å•è®¡ç®—
        tp = np.sum((pred_binary == 1) & (gt_flat == 1))
        fp = np.sum((pred_binary == 1) & (gt_flat == 0))
        fn = np.sum((pred_binary == 0) & (gt_flat == 1))
        tn = np.sum((pred_binary == 0) & (gt_flat == 0))
    
    epsilon = 2.22045e-16
    
    # è®¡ç®—æŒ‡æ ‡
    accuracy = (tp + tn) / (tp + tn + fp + fn + epsilon)
    sensitivity = tp / (tp + fn + epsilon)  # Recall
    precision = tp / (tp + fp + epsilon)
    f1_score = (2 * sensitivity * precision) / (sensitivity + precision + epsilon)
    
    return {
        'f1': f1_score,
        'precision': precision,
        'recall': sensitivity,
        'accuracy': accuracy,
        'tp': int(tp),
        'fp': int(fp),
        'fn': int(fn),
        'tn': int(tn)
    }


def create_overlay_image(original_image, prediction, ground_truth=None, colors=None):
    """åˆ›å»ºå åŠ å¯è§†åŒ–å›¾åƒ"""
    if colors is None:
        colors = {
            'prediction': [0, 1, 0],      # ç»¿è‰² - é¢„æµ‹
            'ground_truth': [1, 0, 0],    # çº¢è‰² - çœŸå®æ ‡ç­¾
            'both': [1, 1, 0],            # é»„è‰² - é‡å åŒºåŸŸ
            'alpha': 0.6                  # é€æ˜åº¦
        }
    
    # ç¡®ä¿è¾“å…¥æ˜¯numpyæ•°ç»„
    if isinstance(original_image, torch.Tensor):
        original_image = original_image.cpu().numpy()
    if isinstance(prediction, torch.Tensor):
        prediction = prediction.cpu().numpy()
    if ground_truth is not None and isinstance(ground_truth, torch.Tensor):
        ground_truth = ground_truth.cpu().numpy()
    
    # è½¬æ¢ä¸ºRGBæ ¼å¼ [H, W, 3]
    if original_image.ndim == 3 and original_image.shape[0] == 3:
        original_image = original_image.transpose(1, 2, 0)
    
    # åˆ›å»ºå åŠ å›¾åƒ
    overlay = original_image.copy()
    
    # äºŒå€¼åŒ–é¢„æµ‹ç»“æœ
    pred_binary = prediction > 0.5
    
    if ground_truth is not None:
        # äºŒå€¼åŒ–çœŸå®æ ‡ç­¾
        gt_binary = ground_truth > 0.5
        
        # åˆ›å»ºä¸åŒåŒºåŸŸçš„æ©ç 
        both_mask = pred_binary & gt_binary      # ä¸¤è€…éƒ½æœ‰ - é»„è‰²
        pred_only = pred_binary & (~gt_binary)   # åªæœ‰é¢„æµ‹ - ç»¿è‰²
        gt_only = gt_binary & (~pred_binary)     # åªæœ‰çœŸå®æ ‡ç­¾ - çº¢è‰²
        
        # åº”ç”¨é¢œè‰²
        alpha = colors['alpha']
        
        # é»„è‰²åŒºåŸŸ (é‡å )
        overlay[both_mask] = (1 - alpha) * overlay[both_mask] + alpha * np.array(colors['both'])
        
        # ç»¿è‰²åŒºåŸŸ (ä»…é¢„æµ‹)
        overlay[pred_only] = (1 - alpha) * overlay[pred_only] + alpha * np.array(colors['prediction'])
        
        # çº¢è‰²åŒºåŸŸ (ä»…çœŸå®æ ‡ç­¾)
        overlay[gt_only] = (1 - alpha) * overlay[gt_only] + alpha * np.array(colors['ground_truth'])
        
    else:
        # åªæœ‰é¢„æµ‹ç»“æœ
        alpha = colors['alpha']
        overlay[pred_binary] = (1 - alpha) * overlay[pred_binary] + alpha * np.array(colors['prediction'])
    
    return np.clip(overlay, 0, 1)


def create_improvement_overlay(original_image, fsg_prediction, refined_prediction, ground_truth):
    """åˆ›å»ºæ˜¾ç¤ºç»†åŒ–æ”¹è¿›æ•ˆæœçš„å åŠ å›¾"""
    # ç¡®ä¿è¾“å…¥æ˜¯numpyæ•°ç»„
    if isinstance(original_image, torch.Tensor):
        original_image = original_image.cpu().numpy()
    if isinstance(fsg_prediction, torch.Tensor):
        fsg_prediction = fsg_prediction.cpu().numpy()
    if isinstance(refined_prediction, torch.Tensor):
        refined_prediction = refined_prediction.cpu().numpy()
    if isinstance(ground_truth, torch.Tensor):
        ground_truth = ground_truth.cpu().numpy()
    
    # è½¬æ¢ä¸ºRGBæ ¼å¼
    if original_image.ndim == 3 and original_image.shape[0] == 3:
        original_image = original_image.transpose(1, 2, 0)
    
    # äºŒå€¼åŒ–
    fsg_binary = fsg_prediction > 0.5
    refined_binary = refined_prediction > 0.5
    gt_binary = ground_truth > 0.5
    
    # è®¡ç®—å˜åŒ–åŒºåŸŸ
    added_pixels = refined_binary & (~fsg_binary)     # ç»†åŒ–æ–°å¢çš„åƒç´ 
    removed_pixels = fsg_binary & (~refined_binary)   # ç»†åŒ–ç§»é™¤çš„åƒç´ 
    
    # åˆ†ææ–°å¢åƒç´ çš„æ­£ç¡®æ€§
    added_correct = added_pixels & gt_binary          # æ–°å¢çš„æ­£ç¡®åƒç´ ï¼ˆçœŸæ­£çš„æ”¹è¿›ï¼‰
    added_incorrect = added_pixels & (~gt_binary)     # æ–°å¢çš„é”™è¯¯åƒç´ ï¼ˆå‡é˜³æ€§å¢åŠ ï¼‰
    
    # åˆ†æç§»é™¤åƒç´ çš„å½±å“
    removed_correct = removed_pixels & gt_binary      # ç§»é™¤çš„æ­£ç¡®åƒç´ ï¼ˆçœŸé˜³æ€§ä¸¢å¤±ï¼‰
    removed_incorrect = removed_pixels & (~gt_binary) # ç§»é™¤çš„é”™è¯¯åƒç´ ï¼ˆå‡é˜³æ€§å‡å°‘ï¼Œå¥½äº‹ï¼‰
    
    # åˆ›å»ºå åŠ å›¾åƒ
    overlay = original_image.copy()
    alpha = 0.7
    
    # åº”ç”¨é¢œè‰²ç¼–ç 
    overlay[added_correct] = (1 - alpha) * overlay[added_correct] + alpha * np.array([0, 1, 0])      # ç»¿è‰² - æ­£ç¡®æ”¹è¿›
    overlay[added_incorrect] = (1 - alpha) * overlay[added_incorrect] + alpha * np.array([1, 0, 0])  # çº¢è‰² - é”™è¯¯å¢åŠ 
    overlay[removed_correct] = (1 - alpha) * overlay[removed_correct] + alpha * np.array([0, 0, 1])  # è“è‰² - æ­£ç¡®ä¸¢å¤±
    overlay[removed_incorrect] = (1 - alpha) * overlay[removed_incorrect] + alpha * np.array([1, 1, 0]) # é»„è‰² - é”™è¯¯å‡å°‘
    
    # ç»Ÿè®¡ä¿¡æ¯
    improvement_stats = {
        'added_correct': int(added_correct.sum()),
        'added_incorrect': int(added_incorrect.sum()),
        'removed_correct': int(removed_correct.sum()),
        'removed_incorrect': int(removed_incorrect.sum()),
        'net_improvement': int(added_correct.sum() - removed_correct.sum()),
        'net_false_positive_change': int(added_incorrect.sum() - removed_incorrect.sum())
    }
    
    return np.clip(overlay, 0, 1), improvement_stats


def create_multi_output_comparison_overlay(original_image, out1_result, out2_result, out3_result):
    """åˆ›å»ºå¤šè¾“å‡ºå¯¹æ¯”çš„å åŠ å›¾"""
    # ç¡®ä¿è¾“å…¥æ˜¯numpyæ•°ç»„
    if isinstance(original_image, torch.Tensor):
        original_image = original_image.cpu().numpy()
    
    # è½¬æ¢ä¸ºRGBæ ¼å¼
    if original_image.ndim == 3 and original_image.shape[0] == 3:
        original_image = original_image.transpose(1, 2, 0)
    
    # åˆ›å»ºå åŠ å›¾åƒ
    overlay = original_image.copy()
    
    # äºŒå€¼åŒ–
    out1_binary = out1_result > 0.5
    out2_binary = out2_result > 0.5
    out3_binary = out3_result > 0.5
    
    # åˆ›å»ºä¸åŒåŒºåŸŸçš„æ©ç 
    all_three = out1_binary & out2_binary & out3_binary     # ä¸‰ä¸ªéƒ½æœ‰ - ç™½è‰²
    out1_and_2 = out1_binary & out2_binary & (~out3_binary) # out1å’Œout2 - é»„è‰²
    out1_and_3 = out1_binary & out3_binary & (~out2_binary) # out1å’Œout3 - ç´«è‰²
    out2_and_3 = out2_binary & out3_binary & (~out1_binary) # out2å’Œout3 - é’è‰²
    out1_only = out1_binary & (~out2_binary) & (~out3_binary) # ä»…out1 - ç»¿è‰²
    out2_only = out2_binary & (~out1_binary) & (~out3_binary) # ä»…out2 - çº¢è‰²
    out3_only = out3_binary & (~out1_binary) & (~out2_binary) # ä»…out3 - è“è‰²
    
    # åº”ç”¨é¢œè‰²
    alpha = 0.7
    overlay[all_three] = (1 - alpha) * overlay[all_three] + alpha * np.array([1, 1, 1])      # ç™½è‰²
    overlay[out1_and_2] = (1 - alpha) * overlay[out1_and_2] + alpha * np.array([1, 1, 0])    # é»„è‰²
    overlay[out1_and_3] = (1 - alpha) * overlay[out1_and_3] + alpha * np.array([1, 0, 1])    # ç´«è‰²
    overlay[out2_and_3] = (1 - alpha) * overlay[out2_and_3] + alpha * np.array([0, 1, 1])    # é’è‰²
    overlay[out1_only] = (1 - alpha) * overlay[out1_only] + alpha * np.array([0, 1, 0])      # ç»¿è‰²
    overlay[out2_only] = (1 - alpha) * overlay[out2_only] + alpha * np.array([1, 0, 0])      # çº¢è‰²
    overlay[out3_only] = (1 - alpha) * overlay[out3_only] + alpha * np.array([0, 0, 1])      # è“è‰²
    
    return np.clip(overlay, 0, 1)


def load_fsg_model(model_path, device):
    """åŠ è½½FSGæ¨¡å‹"""
    model = FSGNet(channel=3, n_classes=1, base_c=64, depths=[3, 3, 9, 3], kernel_size=3)
    
    # åŠ è½½æƒé‡
    checkpoint = torch.load(model_path, map_location='cpu')
    
    # å¤„ç†DataParallelä¿å­˜çš„æƒé‡ (å»æ‰module.FSGNet.å‰ç¼€)
    state_dict = {}
    for key, value in checkpoint.items():
        if key.startswith('module.FSGNet.'):
            # å»æ‰ 'module.FSGNet.' å‰ç¼€
            new_key = key[len('module.FSGNet.'):]
            state_dict[new_key] = value
        elif key.startswith('module.'):
            # å»æ‰ 'module.' å‰ç¼€
            new_key = key[len('module.'):]
            state_dict[new_key] = value
        else:
            state_dict[key] = value
    
    model.load_state_dict(state_dict)
    model.to(device)
    model.eval()
    print(f"Successfully loaded FSG model with {len(state_dict)} parameters")
    return model


def find_ground_truth(img_file, gt_dir):
    """æŸ¥æ‰¾å¯¹åº”çš„çœŸå®æ ‡ç­¾æ–‡ä»¶"""
    base_name = os.path.splitext(img_file)[0]
    
    # DRIVEæ•°æ®é›†çš„æ ‡ç­¾å‘½åæ¨¡å¼
    gt_name = f"{base_name}_manual1.png"
    gt_path = os.path.join(gt_dir, gt_name)
    
    if os.path.exists(gt_path):
        return gt_path
    return None


def fixed_individual_outputs_inference():
    # é…ç½® - ä¸åŸå§‹inferenceä¿æŒä¸€è‡´
    fsg_model_path = '/root/FSG-Net-pytorch/model_ckpts/FSG-Net-DRIVE.pt'
    val_x_path = "/root/FSG-Net-pytorch/data/DRIVE/val/input"
    val_y_path = "/root/FSG-Net-pytorch/data/DRIVE/val/label"  # æ³¨æ„æ˜¯labelä¸æ˜¯gt
    
    if not os.path.exists(val_x_path):
        print(f"Input path not found: {val_x_path}")
        return
    if not os.path.exists(val_y_path):
        print(f"Label path not found: {val_y_path}")
        return
    
    # è¾“å‡ºç›®å½•
    output_dir = './fixed_individual_outputs_comparison'
    
    # åŒºåŸŸç”Ÿé•¿å‚æ•°
    mu_f = 0.0789
    sigma_f = 0.0774
    alpha = 1.0
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    
    # åŠ è½½FSGæ¨¡å‹
    print("Loading FSG-Net model...")
    fsg_model = load_fsg_model(fsg_model_path, device)
    
    # åˆå§‹åŒ–åŒºåŸŸç”Ÿé•¿
    region_grower = SimpleRegionGrowing(mu_f, sigma_f, alpha)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # ä¸ºæ¯ä¸ªè¾“å‡ºåˆ›å»ºå­ç›®å½•
    for out_name in ['out1', 'out2', 'out3']:
        os.makedirs(f"{output_dir}/{out_name}_original", exist_ok=True)
        os.makedirs(f"{output_dir}/{out_name}_refined", exist_ok=True)
        os.makedirs(f"{output_dir}/{out_name}_improvement", exist_ok=True)
        os.makedirs(f"{output_dir}/{out_name}_vs_gt", exist_ok=True)
    
    # å¯¹æ¯”å›¾
    os.makedirs(f"{output_dir}/multi_output_comparison", exist_ok=True)
    os.makedirs(f"{output_dir}/refined_comparison", exist_ok=True)
    
    # æŸ¥æ‰¾å›¾åƒæ–‡ä»¶
    all_files = os.listdir(val_x_path)
    image_files = [f for f in all_files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff', '.bmp'))]
    
    if len(image_files) == 0:
        print("No image files found!")
        return
    
    print(f"Processing {len(image_files)} images...")
    
    # ç»Ÿè®¡æ‰€æœ‰å›¾åƒçš„æŒ‡æ ‡
    all_metrics = {
        'out1_original': [], 'out1_refined': [],
        'out2_original': [], 'out2_refined': [],
        'out3_original': [], 'out3_refined': []
    }
    
    all_improvement_stats = {
        'out1': [], 'out2': [], 'out3': []
    }
    
    # å¤„ç†æ¯å¼ å›¾åƒ
    for i, img_file in enumerate(image_files):
        print(f"\n{'='*80}")
        print(f"Processing {i+1}/{len(image_files)}: {img_file}")
        print("="*80)
        
        try:
            # åŠ è½½å›¾åƒ
            img_path = os.path.join(val_x_path, img_file)
            image = Image.open(img_path).convert('RGB')
            print(f"  Original image size: {image.size}")
            
            # æŒ‰ç…§åŸå§‹dataloaderæ–¹å¼é¢„å¤„ç†å›¾åƒ
            img_tensor = preprocess_image_like_original(image)
            img_tensor = img_tensor.unsqueeze(0).to(device)  # æ·»åŠ batchç»´åº¦
            print(f"  Processed tensor shape: {img_tensor.shape}")
            
            # æŸ¥æ‰¾å¯¹åº”çš„çœŸå®æ ‡ç­¾
            gt_path = find_ground_truth(img_file, val_y_path)
            ground_truth = None
            if gt_path:
                try:
                    gt_image = Image.open(gt_path).convert('L')
                    print(f"  Original GT size: {gt_image.size}")
                    
                    # æŒ‰ç…§åŸå§‹dataloaderæ–¹å¼é¢„å¤„ç†æ ‡ç­¾
                    gt_tensor = preprocess_target_like_original(gt_image)
                    ground_truth = gt_tensor.squeeze().numpy()  # [H, W]
                    print(f"  Processed GT shape: {ground_truth.shape}")
                    print(f"  GT unique values: {np.unique(ground_truth)}")
                    print(f"  Found ground truth: {os.path.basename(gt_path)}")
                except Exception as e:
                    print(f"  Error loading ground truth: {e}")
                    ground_truth = None
            else:
                print(f"  No ground truth found for {img_file}")
            
            # FSGæ¨ç† - è·å–ä¸‰ä¸ªè¾“å‡º
            with torch.no_grad():
                fsg_out1, fsg_out2, fsg_out3 = fsg_model(img_tensor)
                
                # è½¬æ¢ä¸ºnumpy
                out1 = fsg_out1.squeeze().cpu().numpy()  # [H, W]
                out2 = fsg_out2.squeeze().cpu().numpy()  # [H, W]
                out3 = fsg_out3.squeeze().cpu().numpy()  # [H, W]
                
                outputs = {
                    'out1': out1,
                    'out2': out2, 
                    'out3': out3
                }
                
                print(f"  Output shapes - out1: {out1.shape}, out2: {out2.shape}, out3: {out3.shape}")
                for name, output in outputs.items():
                    print(f"  {name} range: [{output.min():.3f}, {output.max():.3f}]")
            
            # æ¸…é™¤ç¼“å­˜ï¼Œä¸ºæ–°å›¾åƒå‡†å¤‡
            region_grower.clear_cache()
            
            # å¯¹æ¯ä¸ªè¾“å‡ºè¿›è¡ŒåŒºåŸŸç”Ÿé•¿ç»†åŒ–
            original_tensor = img_tensor.squeeze()  # [3, H, W]
            refined_outputs = {}
            binary_outputs = {}
            grown_outputs = {}
            thresholds = {}
            
            print(f"\n=== Individual Output Refinement ===")
            for out_name, output in outputs.items():
                print(f"\n--- Refining {out_name.upper()} ---")
                refined, binary, grown, threshold = region_grower.refine_prediction(
                    output, original_tensor, out_name
                )
                refined_outputs[out_name] = refined
                binary_outputs[out_name] = binary
                grown_outputs[out_name] = grown
                thresholds[out_name] = threshold
            
            # ä¿å­˜åŸå§‹è¾“å‡ºå’Œç»†åŒ–ç»“æœ
            base_name = os.path.splitext(img_file)[0]
            
            for out_name in ['out1', 'out2', 'out3']:
                # ä¿å­˜åŸå§‹è¾“å‡º
                original_img = (outputs[out_name] * 255).astype(np.uint8)
                Image.fromarray(original_img).save(f"{output_dir}/{out_name}_original/{base_name}_{out_name}.png")
                
                # ä¿å­˜ç»†åŒ–ç»“æœ
                refined_img = (refined_outputs[out_name] * 255).astype(np.uint8)
                Image.fromarray(refined_img).save(f"{output_dir}/{out_name}_refined/{base_name}_{out_name}_refined.png")
            
            # è®¡ç®—æŒ‡æ ‡å¹¶åˆ›å»ºå¯è§†åŒ–ï¼ˆå¦‚æœæœ‰çœŸå®æ ‡ç­¾ï¼‰
            if ground_truth is not None:
                print(f"\n=== Metrics Comparison (Using Original Calculation) ===")
                
                # è®¡ç®—æŒ‡æ ‡
                for out_name in ['out1', 'out2', 'out3']:
                    # åŸå§‹è¾“å‡ºæŒ‡æ ‡
                    original_metrics = calculate_metrics_like_original(outputs[out_name], ground_truth)
                    all_metrics[f'{out_name}_original'].append(original_metrics)
                    
                    # ç»†åŒ–è¾“å‡ºæŒ‡æ ‡
                    refined_metrics = calculate_metrics_like_original(refined_outputs[out_name], ground_truth)
                    all_metrics[f'{out_name}_refined'].append(refined_metrics)
                    
                    print(f"\n  {out_name.upper()} Metrics:")
                    print(f"    Original - F1: {original_metrics['f1']:.4f}, Precision: {original_metrics['precision']:.4f}, Recall: {original_metrics['recall']:.4f}")
                    print(f"    Refined  - F1: {refined_metrics['f1']:.4f}, Precision: {refined_metrics['precision']:.4f}, Recall: {refined_metrics['recall']:.4f}")
                    print(f"    F1 Change: {refined_metrics['f1'] - original_metrics['f1']:+.4f}")
                    
                    # åˆ›å»ºæ”¹è¿›æ•ˆæœå›¾
                    # éœ€è¦åå½’ä¸€åŒ–å›¾åƒç”¨äºå¯è§†åŒ–
                    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
                    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
                    vis_image = original_tensor * std + mean
                    vis_image = torch.clamp(vis_image, 0, 1).numpy()
                    
                    improvement_overlay, improvement_stats = create_improvement_overlay(
                        vis_image, outputs[out_name], refined_outputs[out_name], ground_truth
                    )
                    improvement_img = (improvement_overlay * 255).astype(np.uint8)
                    Image.fromarray(improvement_img).save(f"{output_dir}/{out_name}_improvement/{base_name}_{out_name}_improvement.png")
                    
                    # ä¿å­˜æ”¹è¿›ç»Ÿè®¡
                    all_improvement_stats[out_name].append(improvement_stats)
                    
                    print(f"    Improvement Stats:")
                    print(f"      âœ… æ–°å¢æ­£ç¡®: {improvement_stats['added_correct']}")
                    print(f"      âŒ æ–°å¢é”™è¯¯: {improvement_stats['added_incorrect']}")
                    print(f"      ğŸ“ˆ å‡€æ”¹è¿›: {improvement_stats['net_improvement']}")
                    print(f"      ğŸ“Š å‡é˜³æ€§å‡€å˜åŒ–: {improvement_stats['net_false_positive_change']}")
                    
                    # åˆ›å»ºä¸GTå¯¹æ¯”å›¾
                    gt_overlay = create_overlay_image(vis_image, refined_outputs[out_name], ground_truth)
                    gt_overlay_img = (gt_overlay * 255).astype(np.uint8)
                    Image.fromarray(gt_overlay_img).save(f"{output_dir}/{out_name}_vs_gt/{base_name}_{out_name}_vs_gt.png")
            
            # åˆ›å»ºå¤šè¾“å‡ºå¯¹æ¯”å›¾
            # ä½¿ç”¨åå½’ä¸€åŒ–çš„å›¾åƒç”¨äºå¯è§†åŒ–
            if ground_truth is not None:
                mean = torch.tensor([0.485, 0.456, 0.406], device=original_tensor.device).view(3, 1, 1)
                std = torch.tensor([0.229, 0.224, 0.225], device=original_tensor.device).view(3, 1, 1)
                vis_image = original_tensor * std + mean
                vis_image = torch.clamp(vis_image, 0, 1).cpu().numpy()
            else:
                # å¦‚æœæ²¡æœ‰GTï¼Œä½¿ç”¨ç®€å•çš„å½’ä¸€åŒ–
                vis_image = (original_tensor.cpu().numpy() + 1) / 2  # å‡è®¾èŒƒå›´æ˜¯[-1,1]
            
            # åŸå§‹è¾“å‡ºå¯¹æ¯”
            multi_original_overlay = create_multi_output_comparison_overlay(
                vis_image, outputs['out1'], outputs['out2'], outputs['out3']
            )
            multi_original_img = (multi_original_overlay * 255).astype(np.uint8)
            Image.fromarray(multi_original_img).save(f"{output_dir}/multi_output_comparison/{base_name}_original_comparison.png")
            
            # ç»†åŒ–è¾“å‡ºå¯¹æ¯”
            multi_refined_overlay = create_multi_output_comparison_overlay(
                vis_image, refined_outputs['out1'], refined_outputs['out2'], refined_outputs['out3']
            )
            multi_refined_img = (multi_refined_overlay * 255).astype(np.uint8)
            Image.fromarray(multi_refined_img).save(f"{output_dir}/refined_comparison/{base_name}_refined_comparison.png")
            
            print(f"\n  Results saved for {base_name}")
            
        except Exception as e:
            print(f"  Error processing {img_file}: {str(e)}")
            import traceback
            traceback.print_exc()
            continue
    
    # è®¡ç®—å¹¶æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
    print(f"\n{'='*80}")
    print("OVERALL STATISTICS - FIXED TO MATCH ORIGINAL INFERENCE")
    print("="*80)
    
    if len(all_metrics['out1_original']) > 0:
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        print(f"\nğŸ“Š Average Metrics Comparison:")
        print(f"{'Output':<8} {'Type':<10} {'F1':<8} {'Precision':<10} {'Recall':<8} {'Accuracy':<10}")
        print("-" * 60)
        
        for out_name in ['out1', 'out2', 'out3']:
            # åŸå§‹æŒ‡æ ‡
            orig_metrics = all_metrics[f'{out_name}_original']
            if orig_metrics:
                avg_f1_orig = np.mean([m['f1'] for m in orig_metrics])
                avg_prec_orig = np.mean([m['precision'] for m in orig_metrics])
                avg_recall_orig = np.mean([m['recall'] for m in orig_metrics])
                avg_acc_orig = np.mean([m['accuracy'] for m in orig_metrics])
                
                print(f"{out_name.upper():<8} {'Original':<10} {avg_f1_orig:<8.4f} {avg_prec_orig:<10.4f} {avg_recall_orig:<8.4f} {avg_acc_orig:<10.4f}")
            
            # ç»†åŒ–æŒ‡æ ‡
            ref_metrics = all_metrics[f'{out_name}_refined']
            if ref_metrics:
                avg_f1_ref = np.mean([m['f1'] for m in ref_metrics])
                avg_prec_ref = np.mean([m['precision'] for m in ref_metrics])
                avg_recall_ref = np.mean([m['recall'] for m in ref_metrics])
                avg_acc_ref = np.mean([m['accuracy'] for m in ref_metrics])
                
                print(f"{'':<8} {'Refined':<10} {avg_f1_ref:<8.4f} {avg_prec_ref:<10.4f} {avg_recall_ref:<8.4f} {avg_acc_ref:<10.4f}")
                
                # è®¡ç®—æ”¹è¿›
                if orig_metrics:
                    f1_improvement = avg_f1_ref - avg_f1_orig
                    print(f"{'':<8} {'Change':<10} {f1_improvement:+<8.4f}")
            
            print()
        
        # æ£€æŸ¥æ˜¯å¦F1åˆ†æ•°ç°åœ¨ä¸åŸå§‹inferenceä¸€è‡´
        print(f"\nğŸ” F1 Score Verification:")
        for out_name in ['out1', 'out2', 'out3']:
            orig_metrics = all_metrics[f'{out_name}_original']
            if orig_metrics:
                avg_f1 = np.mean([m['f1'] for m in orig_metrics])
                print(f"  {out_name.upper()} Original F1: {avg_f1:.4f}")
                if avg_f1 > 0.8:
                    print(f"    âœ… è¿™ä¸ªF1åˆ†æ•°ä¸ä½ çš„åŸå§‹inferenceæ¥è¿‘!")
                else:
                    print(f"    âš ï¸  F1åˆ†æ•°ä»ç„¶åä½ï¼Œå¯èƒ½è¿˜æœ‰å…¶ä»–å·®å¼‚")
        
        # æ”¹è¿›ç»Ÿè®¡æ±‡æ€»
        print(f"\nğŸ” Region Growing Improvement Summary:")
        print(f"{'Output':<8} {'Total Addedâœ…':<12} {'Total IncorrectâŒ':<15} {'Net ImprovementğŸ“ˆ':<18} {'False Pos ChangeğŸ“Š':<18}")
        print("-" * 80)
        
        for out_name in ['out1', 'out2', 'out3']:
            stats_list = all_improvement_stats[out_name]
            if stats_list:
                total_added_correct = sum([s['added_correct'] for s in stats_list])
                total_added_incorrect = sum([s['added_incorrect'] for s in stats_list])
                total_net_improvement = sum([s['net_improvement'] for s in stats_list])
                total_fp_change = sum([s['net_false_positive_change'] for s in stats_list])
                
                print(f"{out_name.upper():<8} {total_added_correct:<12} {total_added_incorrect:<15} {total_net_improvement:<18} {total_fp_change:<18}")
        
        # æ’ååˆ†æ
        print(f"\nğŸ† Performance Ranking:")
        
        # æŒ‰å¹³å‡F1åˆ†æ•°æ’åï¼ˆåŸå§‹ï¼‰
        original_f1_scores = {}
        refined_f1_scores = {}
        improvement_scores = {}
        
        for out_name in ['out1', 'out2', 'out3']:
            orig_metrics = all_metrics[f'{out_name}_original']
            ref_metrics = all_metrics[f'{out_name}_refined']
            
            if orig_metrics and ref_metrics:
                orig_f1 = np.mean([m['f1'] for m in orig_metrics])
                ref_f1 = np.mean([m['f1'] for m in ref_metrics])
                improvement = ref_f1 - orig_f1
                
                original_f1_scores[out_name] = orig_f1
                refined_f1_scores[out_name] = ref_f1
                improvement_scores[out_name] = improvement
        
        # æ’åºå¹¶æ˜¾ç¤º
        if original_f1_scores:
            print(f"\n  Original F1 Ranking:")
            sorted_orig = sorted(original_f1_scores.items(), key=lambda x: x[1], reverse=True)
            for rank, (out_name, score) in enumerate(sorted_orig, 1):
                print(f"    {rank}. {out_name.upper()}: {score:.4f}")
            
            print(f"\n  Refined F1 Ranking:")
            sorted_ref = sorted(refined_f1_scores.items(), key=lambda x: x[1], reverse=True)
            for rank, (out_name, score) in enumerate(sorted_ref, 1):
                print(f"    {rank}. {out_name.upper()}: {score:.4f}")
            
            print(f"\n  F1 Improvement Ranking:")
            sorted_imp = sorted(improvement_scores.items(), key=lambda x: x[1], reverse=True)
            for rank, (out_name, score) in enumerate(sorted_imp, 1):
                print(f"    {rank}. {out_name.upper()}: {score:+.4f}")
    
    print(f"\n{'='*80}")
    print("RESULTS SUMMARY")
    print("="*80)
    print(f"âœ… All results saved to: {output_dir}")
    print(f"\nğŸ“ Directory Structure:")
    print(f"  - out1_original/     (Out1åŸå§‹è¾“å‡º)")
    print(f"  - out1_refined/      (Out1ç»†åŒ–ç»“æœ)")
    print(f"  - out1_improvement/  (Out1æ”¹è¿›æ•ˆæœå›¾)")
    print(f"  - out1_vs_gt/        (Out1ä¸GTå¯¹æ¯”)")
    print(f"  - out2_*/ out3_*/    (Out2å’ŒOut3çš„ç›¸åº”ç»“æœ)")
    print(f"  - multi_output_comparison/  (åŸå§‹è¾“å‡ºå¯¹æ¯”)")
    print(f"  - refined_comparison/       (ç»†åŒ–è¾“å‡ºå¯¹æ¯”)")
    
    print(f"\nğŸ”§ Fixed Issues:")
    print(f"  âœ… ä½¿ç”¨Image2Image_resizeé¢„å¤„ç† (resizeåˆ°608x608)")
    print(f"  âœ… ä½¿ç”¨ImageNetæ ‡å‡†åŒ– (mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])")
    print(f"  âœ… ä½¿ç”¨æ­£ç¡®çš„GTè·¯å¾„ (/val/label/)")
    print(f"  âœ… ä½¿ç”¨åŸå§‹çš„äºŒå€¼åŒ–å¤„ç† (< 128 = 0, >= 128 = 1)")
    print(f"  âœ… ä½¿ç”¨åŸå§‹çš„metricsè®¡ç®—æ–¹æ³•")
    print(f"  âœ… ç§»é™¤äº†åœ†å½¢æ©ç  (ä¸åŸå§‹inferenceä¿æŒä¸€è‡´)")
    
    print(f"\nğŸ“ˆ Expected Results:")
    print(f"  - F1åˆ†æ•°ç°åœ¨åº”è¯¥ä¸ä½ çš„åŸå§‹inference(80+)æ¥è¿‘")
    print(f"  - å¯ä»¥å‡†ç¡®å¯¹æ¯”ä¸‰ä¸ªè¾“å‡ºçš„åŒºåŸŸç”Ÿé•¿æ•ˆæœ")
    print(f"  - åŸºäºçœŸå®çš„F1æ”¹è¿›æ¥é€‰æ‹©æœ€ä½³è¾“å‡º")
    
    print(f"\nğŸ¨ Visualization Color Codes:")
    print(f"  Multi-output comparison:")
    print(f"    ğŸŸ¢ ç»¿è‰² = ä»…Out1")
    print(f"    ğŸ”´ çº¢è‰² = ä»…Out2") 
    print(f"    ğŸ”µ è“è‰² = ä»…Out3")
    print(f"    ğŸŸ¡ é»„è‰² = Out1+Out2")
    print(f"    ğŸŸ£ ç´«è‰² = Out1+Out3")
    print(f"    ğŸ”µ é’è‰² = Out2+Out3")
    print(f"    âšª ç™½è‰² = ä¸‰ä¸ªéƒ½æœ‰")
    
    print(f"\n  Improvement overlay:")
    print(f"    ğŸŸ¢ ç»¿è‰² = ç»†åŒ–æ–°å¢çš„æ­£ç¡®åƒç´  â­")
    print(f"    ğŸ”´ çº¢è‰² = ç»†åŒ–æ–°å¢çš„é”™è¯¯åƒç´ ")
    print(f"    ğŸ”µ è“è‰² = ç»†åŒ–ä¸¢å¤±çš„æ­£ç¡®åƒç´ ")
    print(f"    ğŸŸ¡ é»„è‰² = ç»†åŒ–å‡å°‘çš„é”™è¯¯åƒç´  â­")
    
    print(f"\nğŸ“ˆ Key Insights:")
    print(f"  - F1åˆ†æ•°ç°åœ¨åº”è¯¥æ¥è¿‘ä½ çš„åŸå§‹inferenceç»“æœ")
    print(f"  - æŸ¥çœ‹F1æ”¹è¿›æ’åï¼Œäº†è§£å“ªä¸ªè¾“å‡ºæœ€é€‚åˆåŒºåŸŸç”Ÿé•¿")
    print(f"  - ç»¿è‰²åŒºåŸŸå¤šçš„è¾“å‡ºè¡¨ç¤ºåŒºåŸŸç”Ÿé•¿æ•ˆæœå¥½")
    print(f"  - å¯¹æ¯”å‡€æ”¹è¿›åˆ†æ•°ï¼Œé€‰æ‹©æœ€ä½³è¾“å‡ºè¿›è¡Œåå¤„ç†")


if __name__ == "__main__":
    fixed_individual_outputs_inference()